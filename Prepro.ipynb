{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c00c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# from kan import KAN\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler,MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, balanced_accuracy_score, average_precision_score,\n",
    "    matthews_corrcoef, cohen_kappa_score, brier_score_loss, roc_auc_score\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import random\n",
    "import copy\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# ============================================================\n",
    "# 1. SEEDING (REPRODUCIBILITY)\n",
    "# ============================================================\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58b058",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36450df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform_skewed(df, except_cols):\n",
    "    skew = df.drop(columns=except_cols).skew()\n",
    "    skew_cols = skew[abs(skew) > 0.75].index.tolist()\n",
    "\n",
    "    for col in skew_cols:\n",
    "        df[col] = np.log1p(df[col])\n",
    "    return df\n",
    "\n",
    "def apply_imputation(df):\n",
    "    imputer = IterativeImputer(random_state=42)\n",
    "    arr = imputer.fit_transform(df)\n",
    "    return pd.DataFrame(arr, columns=df.columns)\n",
    "\n",
    "\n",
    "def balance_data(df, label_col=\"Sickness\"):\n",
    "    majority = df[df[label_col] == 1]\n",
    "    minority = df[df[label_col] == 0]\n",
    "\n",
    "    minority_up = resample(minority,\n",
    "                           replace=True,\n",
    "                           n_samples=len(majority),\n",
    "                           random_state=42)\n",
    "\n",
    "    df_bal = pd.concat([majority, minority_up], axis=0)\n",
    "    return df_bal.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8daabd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"IndianLiverPatientDataset(ILPD).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dadf6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IndianLiverPatientDataset(ILPD).csv\")\n",
    "\n",
    "df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})\n",
    "df['Sickness'] = df['Sickness'].replace(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06c3ad97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [134]),\n",
       " (1, [102]),\n",
       " (2, [496]),\n",
       " (3, [367]),\n",
       " (4, [69]),\n",
       " (5, [33, 34]),\n",
       " (6, [474]),\n",
       " (7, [417]),\n",
       " (8, [493]),\n",
       " (9, [105, 106]),\n",
       " (10, [413]),\n",
       " (11, [414]),\n",
       " (12, [41]),\n",
       " (13, [145]),\n",
       " (14, [36]),\n",
       " (15, [532]),\n",
       " (16, [182]),\n",
       " (17, [411])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 18 rows bạn vừa gửi\n",
    "rows_18 = [\n",
    "    [18,0,1.8,0.7,178,35,36,6.8,3.6,1.10,1],\n",
    "    [17,0,0.9,0.2,224,36,45,6.9,4.2,1.55,1],\n",
    "    [24,0,1.0,0.2,189,52,31,8.0,4.8,1.50,1],\n",
    "    [60,0,2.2,1.0,271,45,52,6.1,2.9,0.90,0],\n",
    "    [60,0,0.8,0.2,215,24,17,6.3,3.0,0.90,0],\n",
    "    [38,1,2.6,1.2,410,59,57,5.6,3.0,0.80,0],\n",
    "    [35,0,2.0,1.1,226,33,135,6.0,2.7,0.80,0],\n",
    "    [11,0,0.7,0.1,592,26,29,7.1,4.2,1.40,0],\n",
    "    [65,0,0.7,0.2,265,30,28,5.2,1.8,0.52,0],\n",
    "    [36,0,5.3,2.3,145,32,92,5.1,2.6,1.00,0],\n",
    "    [48,0,0.7,0.2,208,15,30,4.6,2.1,0.80,0],\n",
    "    [65,0,1.4,0.6,260,28,24,5.2,2.2,0.70,0],\n",
    "    [62,0,0.6,0.1,160,42,110,4.9,2.6,1.10,0],\n",
    "    [65,0,0.8,0.2,201,18,22,5.4,2.9,1.10,0],\n",
    "    [17,1,0.7,0.2,145,18,36,7.2,3.9,1.18,0],\n",
    "    [62,0,0.7,0.2,162,12,17,8.2,3.2,0.60,0],\n",
    "    [65,0,1.9,0.8,170,36,43,3.8,1.4,0.58,0],\n",
    "    [23,1,2.3,0.8,509,28,44,6.9,2.9,0.7,0]  \n",
    "]\n",
    "\n",
    "rows_18 = pd.DataFrame(rows_18, columns=df.columns)\n",
    "\n",
    "# Tìm index trong df gốc\n",
    "matching_indices = []\n",
    "\n",
    "for i in range(len(rows_18)):\n",
    "    mask = (df == rows_18.iloc[i]).all(axis=1)\n",
    "    idx = df.index[mask].tolist()\n",
    "    matching_indices.append((i, idx))\n",
    "\n",
    "matching_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c215b589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([332, 15])\n",
      "torch.Size([332, 1])\n",
      "torch.Size([111, 15])\n",
      "torch.Size([111, 1])\n",
      "torch.Size([111, 15])\n",
      "torch.Size([111, 1])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"IndianLiverPatientDataset(ILPD).csv\")\n",
    "\n",
    "df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})\n",
    "df['Sickness'] = df['Sickness'].replace(2, 0)\n",
    "df['A/G'] = df['A/G'].fillna(df['A/G'].mean())\n",
    "\n",
    "df = log_transform_skewed(df, except_cols=[\"Sickness\", \"Gender\"])\n",
    "\n",
    "\n",
    "drop_idx = [134, 102, 496, 367, 33, 34, 474, 417, 493, 105, 106, 413, 414, 145, 36, 532, 182, 411]\n",
    "df= df.drop([i for i in drop_idx if i in df.index], errors=\"ignore\")\n",
    "df=df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"Sickness\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Đoạn này Oversampling, thích thì giữ không thì chỉ cần comment lại là xong. \n",
    "# Tránh test được oversampling, val thì không sao.\n",
    "# train_df = balance_data(train_df)\n",
    "\n",
    "\n",
    "train_split_df, val_split_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.25,                \n",
    "    stratify=train_df[\"Sickness\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "X_train_df = train_split_df.drop(\"Sickness\", axis=1)\n",
    "y_train_df = train_split_df[\"Sickness\"]\n",
    "\n",
    "X_val_df = val_split_df.drop(\"Sickness\", axis=1)\n",
    "y_val_df = val_split_df[\"Sickness\"]\n",
    "\n",
    "X_test_df = test_df.drop(\"Sickness\", axis=1)\n",
    "y_test_df = test_df[\"Sickness\"]\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 5. FIT IMPUTER ONLY ON TRAIN_SPLIT\n",
    "# ==========================================================\n",
    "imputer = IterativeImputer(random_state=42)\n",
    "imputer.fit(X_train_df)               \n",
    "\n",
    "X_train_imp = imputer.transform(X_train_df)\n",
    "X_val_imp   = imputer.transform(X_val_df)\n",
    "X_test_imp  = imputer.transform(X_test_df)\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 6. FIT SCALER ONLY ON TRAIN_SPLIT\n",
    "# ==========================================================\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_imp)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train_imp)\n",
    "X_val_scaled   = scaler.transform(X_val_imp)\n",
    "X_test_scaled  = scaler.transform(X_test_imp)\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 7. FIT PCA, FA, LDA ONLY ON TRAIN_SPLIT\n",
    "# ==========================================================\n",
    "pca = PCA(n_components=7, random_state=42)\n",
    "pca.fit(X_train_scaled)\n",
    "\n",
    "fa = FactorAnalysis(n_components=7, random_state=42)\n",
    "fa.fit(X_train_scaled)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "lda.fit(X_train_scaled, y_train_df)\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 8. Transform all sets\n",
    "# ==========================================================\n",
    "X_train_final = np.concatenate([\n",
    "    pca.transform(X_train_scaled),\n",
    "    fa.transform(X_train_scaled),\n",
    "    lda.transform(X_train_scaled)\n",
    "], axis=1)\n",
    "\n",
    "X_val_final = np.concatenate([\n",
    "    pca.transform(X_val_scaled),\n",
    "    fa.transform(X_val_scaled),\n",
    "    lda.transform(X_val_scaled)\n",
    "], axis=1)\n",
    "\n",
    "X_test_final = np.concatenate([\n",
    "    pca.transform(X_test_scaled),\n",
    "    fa.transform(X_test_scaled),\n",
    "    lda.transform(X_test_scaled)\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 9. Convert to tensors + π/2 scaling\n",
    "# ==========================================================\n",
    "X_train = torch.tensor(X_train_final, dtype=torch.float32)\n",
    "X_val   = torch.tensor(X_val_final,   dtype=torch.float32)\n",
    "X_test  = torch.tensor(X_test_final,  dtype=torch.float32)\n",
    "\n",
    "X_train *= (np.pi / 2)\n",
    "X_val   *= (np.pi / 2)\n",
    "X_test  *= (np.pi / 2)\n",
    "\n",
    "y_train = torch.tensor(y_train_df.values, dtype=torch.float32).unsqueeze(1)\n",
    "y_val   = torch.tensor(y_val_df.values,   dtype=torch.float32).unsqueeze(1)\n",
    "y_test  = torch.tensor(y_test_df.values,  dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 10. DataLoaders\n",
    "# ==========================================================\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train, y_train),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    TensorDataset(X_val, y_val),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(X_test, y_test),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(X_train.size())\n",
    "print(y_train.size())\n",
    "print(X_val.size())\n",
    "print(y_val.size())\n",
    "print(X_test.size())\n",
    "print(y_test.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804555af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
